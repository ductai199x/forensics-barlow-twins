{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 22:34:15.152649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:34:15.203111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:34:15.211537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "print(physical_devices)\n",
    "for physical_device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_device, True)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader, IterableDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(path, prefix=\"\", suffix=\"\", contains=\"\"):\n",
    "    if not os.path.isdir(path):\n",
    "        raise ValueError(f\"{path} is not a valid directory.\")\n",
    "    files = []\n",
    "    for pre, dirs, basenames in os.walk(path):\n",
    "        for name in basenames:\n",
    "            if name.startswith(prefix) and name.endswith(suffix) and contains in name:\n",
    "                files.append(os.path.join(pre, name))\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_STAT_DIR = \"/home/tai/1-workdir/1-deepfake-transformer/src/dataset_stuff/image_generator/db_stats\"\n",
    "PATCH_SIZE = 128\n",
    "ROOT_DB_DIR = f\"/media/nas2/misl_image_db_70_class\"\n",
    "TRAIN_DS_PATH = f\"{ROOT_DB_DIR}/train/{PATCH_SIZE}\"\n",
    "VAL_DS_PATH = f\"{ROOT_DB_DIR}/val/{PATCH_SIZE}\"\n",
    "\n",
    "NUM_CLASSES = 70\n",
    "BATCH_SIZE = 35\n",
    "\n",
    "\n",
    "train_recs = get_all_files(TRAIN_DS_PATH, suffix=\".tfrecord\")\n",
    "val_recs = get_all_files(VAL_DS_PATH, suffix=\".tfrecord\")\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "image_feature_description = {\n",
    "    \"raw\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 22:34:16.925668: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-02 22:34:16.927466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:34:16.927788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:34:16.928007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:34:17.614093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:34:17.614217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:34:17.614314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-02 22:34:17.614913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22280 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def _parse_image_function(example_proto):\n",
    "    parsed_feature = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    image = tf.io.parse_tensor(parsed_feature[\"raw\"], tf.float32)\n",
    "    image = tf.reshape(image, [PATCH_SIZE, PATCH_SIZE, 3])\n",
    "    label = tf.cast(parsed_feature[\"label\"], tf.int64)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "raw_train_set = tf.data.Dataset.from_tensor_slices(train_recs).interleave(\n",
    "    lambda x: tf.data.TFRecordDataset(x).map(_parse_image_function, num_parallel_calls=AUTOTUNE),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    "    cycle_length=BATCH_SIZE,\n",
    "    block_length=BATCH_SIZE,\n",
    ")\n",
    "raw_val_set = tf.data.Dataset.from_tensor_slices(val_recs).interleave(\n",
    "    lambda x: tf.data.TFRecordDataset(x).map(_parse_image_function, num_parallel_calls=AUTOTUNE),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    "    cycle_length=BATCH_SIZE,\n",
    "    block_length=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "\n",
    "train_tfds = raw_train_set.batch(batch_size=BATCH_SIZE, drop_remainder=True).prefetch(buffer_size=AUTOTUNE)\n",
    "val_tfds = raw_val_set.batch(batch_size=BATCH_SIZE, drop_remainder=True).prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyIterableDataset(IterableDataset):\n",
    "    def __init__(self, generator):\n",
    "        self.generator = generator\n",
    "\n",
    "    def process_data(self, generator):\n",
    "        for image, label in generator:\n",
    "            image = torch.from_numpy(image.numpy()).permute(0, 3, 1, 2)  # BHWC->BCHW\n",
    "            label = torch.from_numpy(label.numpy()).long()\n",
    "            yield image, label\n",
    "\n",
    "    def get_stream(self, generator):\n",
    "        return self.process_data(generator)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.get_stream(self.generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_itds = MyIterableDataset(train_tfds)\n",
    "val_itds = MyIterableDataset(val_tfds)\n",
    "train_dl = DataLoader(train_itds, batch_size=None, num_workers=0)\n",
    "val_dl = DataLoader(val_itds, batch_size=None, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from barlow import BarlowTwinsPLWrapper\n",
    "from mislnet import MISLnet, MISLnetPLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/tai/1-workdir/5-forensics-barlow-twins/src/lightning_logs/version_1/checkpoints/mislnet-128-1024=0-epoch=184-val_loss=0.9704.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blab05/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb#ch0000007vscode-remote?line=0'>1</a>\u001b[0m mislnet_config \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blab05/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb#ch0000007vscode-remote?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_size\u001b[39m\u001b[39m\"\u001b[39m: (\u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blab05/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb#ch0000007vscode-remote?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_dim\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1024\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blab05/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb#ch0000007vscode-remote?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdecay_step\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m4\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blab05/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb#ch0000007vscode-remote?line=8'>9</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blab05/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb#ch0000007vscode-remote?line=10'>11</a>\u001b[0m mislnet_ckpt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msrc/lightning_logs/version_1/checkpoints/mislnet-128-1024=0-epoch=184-val_loss=0.9704.ckpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blab05/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb#ch0000007vscode-remote?line=12'>13</a>\u001b[0m mislnet \u001b[39m=\u001b[39m MISLnetPLWrapper\u001b[39m.\u001b[39;49mload_from_checkpoint(mislnet_ckpt, args\u001b[39m=\u001b[39;49mmislnet_config)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blab05/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb#ch0000007vscode-remote?line=14'>15</a>\u001b[0m barlow_config \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blab05/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb#ch0000007vscode-remote?line=15'>16</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfe\u001b[39m\u001b[39m\"\u001b[39m: mislnet,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blab05/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb#ch0000007vscode-remote?line=16'>17</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_size\u001b[39m\u001b[39m\"\u001b[39m: (\u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m), \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blab05/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb#ch0000007vscode-remote?line=22'>23</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m5e-3\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blab05/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb#ch0000007vscode-remote?line=23'>24</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blab05/home/tai/1-workdir/5-forensics-barlow-twins/train_barlow.ipynb#ch0000007vscode-remote?line=25'>26</a>\u001b[0m model \u001b[39m=\u001b[39m BarlowTwinsPLWrapper(barlow_config)\n",
      "File \u001b[0;32m~/1-workdir/pyt_tf2/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:134\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=131'>132</a>\u001b[0m         checkpoint \u001b[39m=\u001b[39m pl_load(checkpoint_path, map_location\u001b[39m=\u001b[39mmap_location)\n\u001b[1;32m    <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=132'>133</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=133'>134</a>\u001b[0m         checkpoint \u001b[39m=\u001b[39m pl_load(checkpoint_path, map_location\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m storage, loc: storage)\n\u001b[1;32m    <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=135'>136</a>\u001b[0m \u001b[39mif\u001b[39;00m hparams_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=136'>137</a>\u001b[0m     extension \u001b[39m=\u001b[39m hparams_file\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/1-workdir/pyt_tf2/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py:37\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mhub\u001b[39m.\u001b[39mload_state_dict_from_url(\u001b[39mstr\u001b[39m(path_or_url), map_location\u001b[39m=\u001b[39mmap_location)\n\u001b[1;32m     <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py?line=35'>36</a>\u001b[0m fs \u001b[39m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py?line=36'>37</a>\u001b[0m \u001b[39mwith\u001b[39;00m fs\u001b[39m.\u001b[39;49mopen(path_or_url, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py?line=37'>38</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mload(f, map_location\u001b[39m=\u001b[39mmap_location)\n",
      "File \u001b[0;32m~/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/spec.py:1009\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/spec.py?line=1006'>1007</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/spec.py?line=1007'>1008</a>\u001b[0m     ac \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mautocommit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intrans)\n\u001b[0;32m-> <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/spec.py?line=1008'>1009</a>\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(\n\u001b[1;32m   <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/spec.py?line=1009'>1010</a>\u001b[0m         path,\n\u001b[1;32m   <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/spec.py?line=1010'>1011</a>\u001b[0m         mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/spec.py?line=1011'>1012</a>\u001b[0m         block_size\u001b[39m=\u001b[39;49mblock_size,\n\u001b[1;32m   <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/spec.py?line=1012'>1013</a>\u001b[0m         autocommit\u001b[39m=\u001b[39;49mac,\n\u001b[1;32m   <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/spec.py?line=1013'>1014</a>\u001b[0m         cache_options\u001b[39m=\u001b[39;49mcache_options,\n\u001b[1;32m   <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/spec.py?line=1014'>1015</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/spec.py?line=1015'>1016</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/spec.py?line=1016'>1017</a>\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/spec.py?line=1017'>1018</a>\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mfsspec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompression\u001b[39;00m \u001b[39mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py:155\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py?line=152'>153</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_mkdir \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py?line=153'>154</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent(path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py?line=154'>155</a>\u001b[0m \u001b[39mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py:250\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py?line=247'>248</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py?line=248'>249</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py?line=249'>250</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open()\n",
      "File \u001b[0;32m~/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py:255\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py?line=252'>253</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf\u001b[39m.\u001b[39mclosed:\n\u001b[1;32m    <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py?line=253'>254</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocommit \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[0;32m--> <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py?line=254'>255</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py?line=255'>256</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression:\n\u001b[1;32m    <a href='file:///home/tai/1-workdir/pyt_tf2/lib/python3.9/site-packages/fsspec/implementations/local.py?line=256'>257</a>\u001b[0m             compress \u001b[39m=\u001b[39m compr[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/tai/1-workdir/5-forensics-barlow-twins/src/lightning_logs/version_1/checkpoints/mislnet-128-1024=0-epoch=184-val_loss=0.9704.ckpt'"
     ]
    }
   ],
   "source": [
    "mislnet_config = {\n",
    "    \"input_size\": (128, 128),\n",
    "    \"output_dim\": 1024,\n",
    "    \"num_classes\": 70,\n",
    "    \"lr\": 1e-3,\n",
    "    \"momentum\": 0.95,\n",
    "    \"decay_rate\": 0.75,\n",
    "    \"decay_step\": 4,\n",
    "}\n",
    "\n",
    "mislnet_ckpt = \"src/lightning_logs/mislnet-128-1024/version_1/checkpoints/mislnet-128-1024=0-epoch=184-val_loss=0.9704.ckpt\"\n",
    "\n",
    "mislnet = MISLnetPLWrapper.load_from_checkpoint(mislnet_ckpt, args=mislnet_config)\n",
    "\n",
    "barlow_config = {\n",
    "    \"fe\": mislnet,\n",
    "    \"input_size\": (128, 128), \n",
    "    \"fe_output_dim\": 1024, \n",
    "    \"proj_output_dim\": 2048,\n",
    "    \"lr\": 1e-3, \n",
    "    \"momentum\": 0.9,\n",
    "    \"decay_rate\": 5e-4,\n",
    "    \"alpha\": 5e-3\n",
    "}\n",
    "\n",
    "model = BarlowTwinsPLWrapper(barlow_config)\n",
    "model_name = \"forensics-barlow-twins\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_ckpt = None\n",
    "\n",
    "resume = False\n",
    "if prev_ckpt:\n",
    "    model = model.load_from_checkpoint(prev_ckpt, args=barlow_config)\n",
    "\n",
    "version = 0\n",
    "monitor_metric = \"val_loss\"\n",
    "log_path = \"src/lightning_logs/barlow_twins\"\n",
    "\n",
    "logger = TensorBoardLogger(save_dir=os.getcwd(), version=version, name=log_path)\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "model_ckpt = ModelCheckpoint(\n",
    "    dirpath=f\"{log_path}/version_{version}/checkpoints\",\n",
    "    monitor=monitor_metric,\n",
    "    filename=f\"{{{model_name}}}-{{epoch:02d}}-{{{monitor_metric}:.4f}}\",\n",
    "    verbose=True,\n",
    "    save_last=True,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=60,\n",
    "    resume_from_checkpoint=prev_ckpt if resume else None,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    weights_summary=\"full\",\n",
    "    logger=logger,\n",
    "    callbacks=[lr_monitor, model_ckpt],\n",
    "    fast_dev_run=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dl, val_dl)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0421650a8a5845f713c56c3ba4f436fc22593ad99b656f8436ea71c2ab26d6c1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('pyt_tf2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
